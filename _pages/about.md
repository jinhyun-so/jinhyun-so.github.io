---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - about/
  - about.html
---

I am a PhD candidate in electrical and computer engineering at USC under the supervision of Professor [Salman Avestimehr](https://www.avestimehr.com/). I am interested in Federated Learning, Privacy-preserving Machine Learning, Large-scale Distributed Computing, and Information Theory.



## Recent News

- (2022-02) Our paper "[FedSpace: An Efficient Federated Learning Framework at Satellites and Ground Stations](https://arxiv.org/abs/2202.01267)" is on arXiv.
- (2022-01) Our paper "[LightSecAgg: a Lightweight and Versatile Design for Secure Aggregation in Federated Learning](https://arxiv.org/abs/2109.14236)" is accepted to [MLSys 2022 - Fifth Conference on Machine Learning and Systems](https://mlsys.org/).
- (2022-01) Our paper "[Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in Federated Learning](https://arxiv.org/abs/2106.03328)" is accepted to [International Workshop on Trustable, Verifiable and Auditable Federated Learning in Conjunction with AAAI 2022 (FL-AAAI-22)](https://federated-learning.org/fl-aaai-2022/).
- (2021-10) Our paper "[Secure Aggregation for Buffered Asynchronous Federated Learning](https://arxiv.org/abs/2110.02177)" is accepted to "[NeurIPS-2021 Workshop on New Frontiers in Federated Learning](https://neurips2021workshopfl.github.io/NFFL-2021/paper.html)".
- (2021-09) Our paper "[LightSecAgg: Rethinking Secure Aggregation in Federated Learning](https://arxiv.org/pdf/2109.14236.pdf)" is accepted to [2021 IEEE Information Theory Workshop (ITW 2021)](http://itw2021.org/?page_id=544).
- (2021-06) I started a PhD internship at **Microsoft Research, Redmond**. I have worked on the project "Distributed Machine Learning Training in Space".
- (2021-06) Our paper "[Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in Federated Learning](https://arxiv.org/abs/2106.03328)" is on arXiv.
- (2021-02) Our paper "[FedML: A Research Library and Benchmark for Federated Machine Learning](https://arxiv.org/abs/2007.13518)" (a shorter version of [**FedML**](https://www.fedml.ai/) white-paper) won the **Baidu Best Paper Award** at [NeurIPS-20 Workshop on Scalability, Privacy, and Security in Federated Learning](http://icfl.cc/SpicyFL/2020).
- (2021-01) Our paper "[Turbo-Aggregate: Breaking the Quadratic Aggregation Barrier in Secure Federated Learning](https://ieeexplore.ieee.org/document/9336021)" is accepted at IEEE Journal on Selected Areas in Information Theory (**JSAIT**).
- (2021-01) Our paper "[CodedPrivateML: A Fast and Privacy-Preserving Framework for Distributed Machine Learning](https://ieeexplore.ieee.org/document/9330572)" is accepted at IEEE Journal on Selected Areas in Information Theory (**JSAIT**).
- (2020-10) Our paper "[Byzantine-Resilient Secure Federated Learning](https://ieeexplore.ieee.org/document/9276464)" is accepted at IEEE Journal on Selected Areas in Communications (**JSAC**).
- (2020-09) Our paper [A Scalable Approach for Privacy-Preserving Collaborative Machine-Learning](https://papers.nips.cc/paper/2020/file/5bf8aaef51c6e0d363cbe554acaf3f20-Paper.pdf) is accepted to Conference on Neural Information Processing Systems (**NeurIPS 2020**)! 
